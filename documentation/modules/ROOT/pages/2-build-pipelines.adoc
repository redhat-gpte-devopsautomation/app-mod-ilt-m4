= 2. Build CI/CD Pipelines - 30 minutes
:imagesdir: ../assets/images

== Goals of this lab

The goal is to build and deploy the modernized customer application to OpenShift using link:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/cicd/index#op-detailed-concepts[OpenShift Pipeline^].

* Use the https://tekton.dev/[Tekton^] Pipeline to build and deploy the new, modernized application using Red Hat JBoss Web Server instead of Apache Tomcat as the runtime.
* Set up the configuration for the *customers* service to connect to the Oracle database VM which is now running on OpenShift Container Platform
* Test the *customers* service

== 2.1. Update Oracle DMBS Connection using Helm

=== 2.1.1. Why OpenShift with Helm?

https://docs.openshift.com/container-platform/4.10/applications/working_with_helm_charts/understanding-helm.html[Helm^] is a package and install manager that standardizes and simplifies packaging and deployment of containerized applications with Kubernetes, anywhere in the hybrid cloud. Helm lets developers package their applications so that they can be easily shared and deployed by anyone in their organization and beyond. 

Helm can also be used to automate *day-1* tasks like installation and basic configuration management for setting up the applications, and some *day-2* operations like performing some simple upgrades and rollbacks.

=== 2.1.2. Update the Helm Chart for a new JDBC configuration

The *customers* application in the OpenShift cluster currently has a connection failure because the application still tries to connect to the Oracle database running on RHV. To fix the issue, you need to update the *JDBC* configuration that points to the migrated Oracle database on OpenShift virtualization.

[IMPORTANT]
====
To save your time to go through the hands-on labs today, our SRE team has already migrated the VM running Oracle database to the OpenShift virtualization in the *retail-%USERID%* project.  
====

The JDBC configuration is currently managed by the _Helm chart_ to automate day 1 & 2 operations for the modernized Globex retail system. Let's go back to the link:https://codeserver-codeserver-user1.apps.cluster-mjkpv.sandbox1648.opentlc.com[VS Code server^] and explore the *helm/customer-tomcat-gitops* directory.

Take a look at `persistence.properties` file to understand how the Helm chart allows you to define the JDBC configuration.

image::gitops-persistence.png[gitops-persistence]

[NOTE]
====
The best developer practice for updating the *JDBC configuration* is that you change the configurations locally in VS Code server. Then, when you commit and push the changes to your Gitea repository, it will trigger the `OpenShift pipeline and GitOps` magically to update OpenShift `ConfigMap` and `Secret` automatically.
====

Access link:https://argocd-server-retail-%USERID%.%SUBDOMAIN%[ArgoCD web console^]. Click on `LOG VIA OPENSHIFT` button.

image::argocd-login.png[argocd-login]

Then, enter your OpenShift login credentials.

* Username: `%USERID%`
* Password: `{openshift-password}`

[NOTE]
====
We'll go deep dive into OpenShift GitOps in terms of the benefits, features, and integration in the next step.
====

You will see that the `customers-tomcat-gitops` status is *Degraded* because the application still refers to the old database hostname (e.g.*oracle-db-database*).

Click on `applications`.

image::argocd-application.png[argocd-application]

Click on `APP DETAILS` to show up the detail page. Then, switch to `PARAMETER` tab to click on `EDIT`.

image::argocd-application-details.png[argocd-application-details]

Replace keys and values of `customerDatabase` with the following data that refer to the Oracle virtual machine on Red Hat OpenShift. It should look like this:

* customerDatabase.hostname: `oracle-database`
* customerDatabase.password: `redhat`

image::argocd-application-update.png[argocd-application-update]

Click on `SAVE`. Then, close the popup window by clicking `X` on the right top.

Now you will see the `OutOfSync` status of the `customers-tomcat-gitops` application because you just only updated the ArgoCD's application parameter that is different than link:https://console-openshift-console.%SUBDOMAIN%/k8s/ns/retail-%USERID%/secrets/customers-secret[customers-secret^] in the retail-%USERID% project. 

image::argocd-application-outofsync.png[argocd-application-outofsync]

Click on `SYNC`. Then, click on `SYNCHRONIZE` on the left popup window.

image::argocd-application-sync.png[argocd-application-sync]

The application should be synced in a second.

image::argocd-application-synced.png[argocd-application-synced]

Go back to the OpenShift web console, reveal the link:https://console-openshift-console.%SUBDOMAIN%/k8s/ns/retail-%USERID%/secrets/customers-secret[customers-secret^]. You will see the updated the JDBC configurations.

image::argocd-application-secret.png[argocd-application-secret]

== 2.2. Run OpenShift Pipelines

=== 2.2.1 Why OpenShift Pipelines?

OpenShift Pipelines provides a *kubernetes-native CI/CD* framework based on https://tekton.dev[Tekton^] to design and run your pipelines, and is designed to run each step of the CI/CD pipeline in its own container, allowing each step to scale independently to meet the demands of the pipeline.

By extending Kubernetes/OpenShift with Custom Resource Definitions (CRDs), OpenShift Pipelines makes CI/CD concepts such as `pipeline`, `task`, and `step` natively in terms of increasing the scalability, security, ease of deployment capabilities of Kubernetes.

image::tekton-concept.png[tekton-concept]

Each of these tasks can be described as follows:

* *Clone Repository* downloads the source code from the target Git repository.
* *Build from Source* builds the application artifact from source code. This task has been tweaked to allow selecting the target subdirectory from the repository in which the target application source is available, allowing to have several application/components available in a single repository. *This way of versioning different services/components is highly discouraged*, as the optimal approach would be to have a dedicated repository for each component since their lifecycle should be independent. Nevertheless, this choice was made to gather all demo materials on a single repository for simplicity purposes.
* *Build Image* uses the Dockerfile packaged on the root directory of an application to build an image and push it to the target registry. The image will be tagged with the short commit hash of the source it contains.
* *Update Manifest* uses the short commit hash tag to update the application manifest in Git and point to the newly built image. Application deployment is then delegated to ArgoCD, which is continuously polling the configuration repository for changes and creates/updates all OpenShift objects accordingly.

The pipeline accepts the following parameters:

* *git-url*: URL of the target Git repository.
* *git-branch*: target branch to work with. (_default: main_)
* *app-subdir*: Subdirectory from the repository in which the application source code is stored.
* *target-namespace*: Namespace/project in which to deploy the application.
* *target-registry*: Registry to push the built image to. (_default: image-registry.openshift-image-registry.svc:5000_)

=== 2.2.2 Execute the Customers Pipelines

In the future we will have a trigger and event listener on the pipeline. But for now you have to kick off the pipeline run manually.

First, open a new browser to access the link:https://console-openshift-console.%SUBDOMAIN%/dev-pipelines/ns/cicd-%USERID%[OpenShift Pipleline^].

Use the following credentials if you haven't logged in to the OpenShift cluster before. 

image::openshift_login.png[openshift_login]

Login using your credentials:

* Username: `%USERID%`
* Password: `{openshift-password}`

Then, you will see pre-defined `java-deployment` in `cicd-%USERID%` project at _Developer perspective_. 

Click on the pipeline.

image::ama-pipeline.png[ama-pipeline]

Click on `Start` in *Actions* dropbox to run the pipeline.

image::ama-pipeline-start.png[ama-pipeline-start]

A *PipelineRun* is how you can start a pipeline and tie it to the Git and image resources that should be used for this specific invocation.

This dialog box is where you bind the final target values for the source repo of the _build-artifact_ step, and the target namespace to deploy in the _update-manifest-and-push_ step. Update the workspaces section using the following value. Click on *Start*.

[NOTE]
====
Leave default values for the other keys such as `git-url, git-branch, app-subdir, target-namespace, and target-registry`.
====

* ws: `customers-pvc` in *PersistentVolumeClaim*

image::ama-pipeline-start-popup.png[ama-pipeline-start-popup]

As soon as you start the *java-deployment-pipeline* pipeline, a _pipelinerun_ is instantiated and pods are created to execute the tasks that are defined in the pipeline. After a few minutes, the pipeline should finish successfully. You can hover over the steps to get a quick snapshot of the stepâ€™s progress, or click on the steps to see detailed logs of the steps.

image::ama-pipeline-complete.png[ama-pipeline-complete]

=== 2.2.3 Add Labels for better Topology View

Globex retail system has deployed multiple microservices to the OpenShift cluster. Each microservices has complex relations with the other microservices and databases. This architecture might not be immediately understandable for developers and SREs. Fortunately OpenShift developer console provides an intuitive `topology` view with helpful labels and annotations. These labels detail the explicit relations among deployed applications in the same namespace.

Add the following labels and annotations to show which _languages_, _frameworks_, and _runtimes_ are used for each application by running the following `oc` commands in terminal on the VS Code server where you logged in to the OpenShift cluster.

Run the following command in the VS Code server terminal.

[.console-input]
[source,bash]
----
oc project retail-%USERID% && \
oc label deployment/inventory app.kubernetes.io/part-of=inventory app.openshift.io/runtime=quarkus --overwrite && \
oc label deployment/postgresql-inventory app.kubernetes.io/part-of=inventory app.openshift.io/runtime=postgresql --overwrite && \
oc annotate deployment/inventory app.openshift.io/connects-to='[{"apiVersion":"apps/v1","kind":"Deployment","name":"postgresql-inventory"}]' --overwrite && \
oc label deployment/orders app.kubernetes.io/part-of=orders app.openshift.io/runtime=spring --overwrite && \
oc label deployment/postgresql-orders app.kubernetes.io/part-of=orders app.openshift.io/runtime=postgresql --overwrite && \
oc annotate deployment/orders app.openshift.io/connects-to='[{"apiVersion":"apps/v1","kind":"Deployment","name":"postgresql-orders"}]' --overwrite && \
oc label deployment/customers app.kubernetes.io/part-of=customers app.openshift.io/runtime=tomcat --overwrite && \
oc annotate deployment/customers app.openshift.io/connects-to='[{"apiVersion":"apps/v1","kind":"VirtualMachine","name":"oracle-database"}]' --overwrite && \
oc label deployment/ordersfrontend app.kubernetes.io/part-of=ordersfrontend app.openshift.io/runtime=nodejs --overwrite && \
oc annotate deployment/ordersfrontend app.openshift.io/connects-to=gateway --overwrite && \
oc label deployment/gateway app.kubernetes.io/part-of=gateway app.openshift.io/runtime=spring --overwrite && \
oc annotate deployment/gateway app.openshift.io/connects-to='["inventory","orders","customers",{"apiVersion":"apps/v1","kind":"Deployment","name":"customers"}]' --overwrite 
----

[NOTE]
====
You might have no connection between `gateway` and `customers`. In that case, you can add the connection by dragging in _Dev Console_.
====

Go back to the link:https://console-openshift-console.%SUBDOMAIN%/topology/ns/retail-%USERID%?view=graph[Topology View^] in `retail-%USERID%` project at Developer perspective, the applications deployment should appear as follows:

image::app-topology.png[app-topology]

Now we need to update the `gateway` application's configuration to connect to the `customers` based on Kubernetes service name rather than the *static IP address*.